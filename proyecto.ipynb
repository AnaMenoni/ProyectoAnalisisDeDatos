{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n","                <p>\n","                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n","                </p>\n","            </div>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["from ucimlrepo import fetch_ucirepo \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from ydata_profiling import ProfileReport\n","import webbrowser\n","import os\n","import numpy as np\n","  \n","df = pd.read_csv(\"Tema_4.csv\")\n","\n","\n","# Paleta de colores personalizada\n","colores = {\n","    'principal': '#0047AB',   \n","    'oscuro': '#00264D',      \n","    'cian': '#00A6ED',        \n","    'dorado': '#C5A100',      \n","    'gris': '#E5E5E5'         \n","}\n","\n","# Aplicar estilo general\n","plt.style.use('default')\n","sns.set_palette([colores['principal']])\n","sns.set_context(\"notebook\", font_scale=1.0)\n","plt.rcParams.update({\n","    'axes.facecolor': 'white',\n","    'axes.edgecolor': colores['oscuro'],\n","    'grid.color': '#cccccc',\n","    'grid.linestyle': '--',\n","    'grid.alpha': 0.6\n","})\n","\n","color_base = colores['principal']\n"]},{"cell_type":"markdown","metadata":{},"source":["# Análisis Exploratorio"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/anamenoni/Library/CloudStorage/OneDrive-UniversidaddeMontevideo/FIUM/Semestre VI FIUM/Analisis de Datos/ProyectoCavelliMenoniPena/ProyectoAnalisisDeDatos/proyecto.ipynb Celda 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anamenoni/Library/CloudStorage/OneDrive-UniversidaddeMontevideo/FIUM/Semestre%20VI%20FIUM/Analisis%20de%20Datos/ProyectoCavelliMenoniPena/ProyectoAnalisisDeDatos/proyecto.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anamenoni/Library/CloudStorage/OneDrive-UniversidaddeMontevideo/FIUM/Semestre%20VI%20FIUM/Analisis%20de%20Datos/ProyectoCavelliMenoniPena/ProyectoAnalisisDeDatos/proyecto.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEl dataset contiene \u001b[39m\u001b[39m{\u001b[39;00mdf\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m filas (registros) y \u001b[39m\u001b[39m{\u001b[39;00mdf\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m columnas\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anamenoni/Library/CloudStorage/OneDrive-UniversidaddeMontevideo/FIUM/Semestre%20VI%20FIUM/Analisis%20de%20Datos/ProyectoCavelliMenoniPena/ProyectoAnalisisDeDatos/proyecto.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m filas \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anamenoni/Library/CloudStorage/OneDrive-UniversidaddeMontevideo/FIUM/Semestre%20VI%20FIUM/Analisis%20de%20Datos/ProyectoCavelliMenoniPena/ProyectoAnalisisDeDatos/proyecto.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m columnas \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["%matplotlib inline\n","\n","print(f\"El dataset contiene {df.shape[0]} filas (registros) y {df.shape[1]} columnas\")\n","\n","filas = df.shape[0]\n","columnas = df.shape[1]\n","total_celdas = df.size\n","\n","info_df = pd.DataFrame({\n","    'Columnas': df.columns,\n","    'Tipo de dato': df.dtypes,\n","    'Valores no nulos': df.notnull().sum(),\n","    'Valores nulos': df.isnull().sum(),\n","    'Porcentaje nulos (%)': (df.isnull().sum() / len(df) * 100).round(2)\n","})\n","\n","display(info_df)\n","\n","print(\"------------------------- VALORES NULOS DEL DATASET ------------------------\")\n","porcentaje_nulos = (df.isna().mean() * 100).sort_values()  # cálculo equivalente y claro\n","\n","plt.figure(figsize=(10,6))\n","plt.barh(porcentaje_nulos.index, porcentaje_nulos.values)\n","plt.xlabel('Porcentaje de valores nulos (%)')\n","plt.ylabel('Variables')\n","plt.title('Porcentaje de valores nulos por variable')\n","\n","# etiquetas con 2 decimales\n","for i, v in enumerate(porcentaje_nulos.values):\n","    plt.text(v + 0.01, i, f\"{v:.2f}%\", va='center')\n","\n","# zoom del eje X para apreciar 4.9–5.1 %\n","minv, maxv = porcentaje_nulos.min(), porcentaje_nulos.max()\n","plt.xlim(minv - 0.05, maxv + 0.05)   # ajusta márgenes si querés más/menos zoom\n","plt.grid(axis='x', linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n","\n","profile = ProfileReport(df, title=\"Tema_4\", explorative=True)\n","profile.to_file(\"Tema_4.html\")\n","\n","archivo_html = os.path.abspath(\"Tema_4.html\")\n","webbrowser.open(f\"file://{archivo_html}\")\n","\n","\n","variables_numericas = ['balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n","variables_binarias = ['default', 'housing', 'loan', 'y']\n","variables_categoricas = ['job', 'marital', 'education', 'contact', 'poutcome']\n","\n","\n","print(\"-------------------- DISTRIBUCIÓN DE VARIABLES NUMÉRICAS CONTÍNUAS --------------------\")\n","\n","# --- BALANCE (escala logarítmica) ---\n","plt.figure(figsize=(6,4))\n","sns.histplot(df['balance'], bins=50, color=color_base, edgecolor='black', kde=False)\n","plt.yscale('log')\n","plt.title('Distribución de la variable Balance', fontsize=11)\n","plt.xlabel('Balance', fontsize=10)\n","plt.ylabel('Frecuencia (escala log)', fontsize=10)\n","plt.grid(axis='y', linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n","\n","\n","# --- DAY ---\n","plt.figure(figsize=(6,4))\n","sns.histplot(df['day'], bins=31, color=color_base, edgecolor='black', kde=False)\n","plt.xticks(range(1,32,2))\n","plt.title('Distribución de la variable Day', fontsize=11)\n","plt.xlabel('Day', fontsize=10)\n","plt.ylabel('Frecuencia', fontsize=10)\n","plt.grid(axis='y', linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n","\n","# --- DURATION ---\n","plt.figure(figsize=(6,4))\n","sns.histplot(df['duration'], bins=40, color=color_base, edgecolor='black', kde=False)\n","plt.xlim(0, 1200)  # evita colas largas\n","plt.title('Distribución de la variable Duration (limitada a 1200s)', fontsize=11)\n","plt.xlabel('Duration (segundos)', fontsize=10)\n","plt.ylabel('Frecuencia', fontsize=10)\n","plt.grid(axis='y', linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n","\n","# --- CAMPAIGN (escala logarítmica en eje Y) ---\n","plt.figure(figsize=(6,4))\n","sns.histplot(df['campaign'], bins=30, color=color_base, edgecolor='black', kde=False)\n","plt.yscale('log')\n","plt.title('Distribución de la variable Campaign', fontsize=11)\n","plt.xlabel('Campaign', fontsize=10)\n","plt.ylabel('Frecuencia (escala log)', fontsize=10)\n","plt.grid(axis='y', linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n","\n","# --- PDAYS (escala logarítmica en eje Y) ---\n","plt.figure(figsize=(6,4))\n","sns.histplot(df['pdays'], bins=50, color=color_base, edgecolor='black', kde=False)\n","plt.xlim(0, 400)  # mantiene enfoque en valores útiles\n","plt.yscale('log')\n","plt.title('Distribución de la variable Pdays', fontsize=11)\n","plt.xlabel('Pdays', fontsize=10)\n","plt.ylabel('Frecuencia (escala log)', fontsize=10)\n","plt.grid(axis='y', linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n","\n","# --- PREVIOUS (escala logarítmica en eje Y) ---\n","plt.figure(figsize=(6,4))\n","sns.histplot(df['previous'], bins=20, color=color_base, edgecolor='black', kde=False)\n","plt.xlim(0, 10)\n","plt.yscale('log')\n","plt.title('Distribución de la variable Previous', fontsize=11)\n","plt.xlabel('Previous', fontsize=10)\n","plt.ylabel('Frecuencia (escala log)', fontsize=10)\n","plt.grid(axis='y', linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"-------------------- DISTRIBUCIÓN DE VARIABLES BINARIAS --------------------\")\n","for col in variables_binarias:\n","    plt.figure(figsize=(5,3))\n","    valores = df[col].value_counts(dropna=False)\n","\n","    sns.barplot(\n","        x=valores.index.astype(str),\n","        y=valores.values,\n","        color=color_base,\n","        edgecolor='black'\n","    )\n","    \n","    plt.ylim(0, valores.max() * 1.15) \n","\n","    plt.title(f'Distribución de la variable {col.capitalize()}', fontsize=11)\n","    plt.xlabel(col.capitalize(), fontsize=10)\n","    plt.ylabel('Frecuencia', fontsize=10)\n","    plt.grid(axis='y', linestyle='--', alpha=0.6)\n","\n","    for i, v in enumerate(valores.values):\n","        plt.text(i, v + (valores.max() * 0.02), str(v), ha='center', fontsize=9, color=colores['oscuro'])\n","    \n","    plt.tight_layout()\n","    plt.show()\n","\n","print(\"-------------------- DISTRIBUCIÓN DE VARIABLES CATEGÓRICAS --------------------\")\n","for col in variables_categoricas:\n","    plt.figure(figsize=(8,4))\n","\n","    valores = df[col].value_counts(dropna=False).sort_values(ascending=False)\n","    \n","    sns.barplot(\n","        x=valores.index.astype(str),\n","        y=valores.values,\n","        color=color_base,\n","        edgecolor='black'\n","    )\n","\n","    plt.ylim(0, valores.max() * 1.20)\n","    plt.title(f'Distribución de la variable {col.capitalize()}', fontsize=11)\n","    plt.xlabel(col.capitalize(), fontsize=10)\n","    plt.ylabel('Frecuencia', fontsize=10)\n","    plt.xticks(rotation=45, ha='right')\n","    plt.grid(axis='y', linestyle='--', alpha=0.6)\n","\n","    for i, v in enumerate(valores.values):\n","        plt.text(i, v + (valores.max() * 0.02), str(v), ha='center', fontsize=9, color=colores['oscuro'])\n","    \n","    plt.tight_layout()\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Pretratamiento de datos - limpieza de datos"]},{"cell_type":"markdown","metadata":{},"source":["### Eliminación de duplicados"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Se eliminaron 10 filas duplicadas.\n"]}],"source":["df_cleaned = df.copy()\n","\n","# Eliminar duplicados 100% iguales\n","duplicados = df.duplicated()\n","num_duplicados = duplicados.sum()\n","if num_duplicados > 0:\n","    df_cleaned = df_cleaned.drop_duplicates()\n","    print(f\"Se eliminaron {num_duplicados} filas duplicadas.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la varible Age"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"-------------------- LIMPIEZA DE LA VARIABLE AGE --------------------\")\n","\n","df_cleaned['age'] = pd.to_numeric(\n","    df_cleaned['age'].replace(['unknown', 'unknown_age', 'NA', 'na', 'None'], np.nan),\n","    errors='coerce'\n",")\n","\n","rango_valido = (df_cleaned['age'] >= 18) & (df_cleaned['age'] <= 100)\n","filas_fuera_rango = df_cleaned.loc[~rango_valido, 'age'].count()\n","\n","df_cleaned = df_cleaned[rango_valido]\n","\n","print(f\"Se eliminaron {filas_fuera_rango} filas con edades fuera del rango [18, 100].\")\n","\n","mediana_edad = df_cleaned['age'].median()\n","df_cleaned['age'].fillna(mediana_edad, inplace=True)\n","\n","print(f\"Se imputaron {df_cleaned['age'].isna().sum()} valores nulos con la mediana ({mediana_edad:.0f} años).\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable Job"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"-------------------- LIMPIEZA DE LA VARIABLE JOB --------------------\")\n","\n","# Verificar valores únicos y frecuencias\n","df_cleaned['job'].value_counts(dropna=False)\n","\n","df_cleaned['job'] = df_cleaned['job'].astype(str).str.strip().str.lower()\n","\n","# Correcciones específicas\n","df_cleaned['job'] = df_cleaned['job'].replace({\n","    'admin.': 'admin',\n","    '12345': 'unknown',   \n","    'nan': 'unknown',   \n","    'none': 'unknown'\n","})\n","\n","# Reemplazar valores nulos reales (NaN) por 'unknown'\n","df_cleaned['job'] = df_cleaned['job'].fillna('unknown')"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de variable Marital"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_cleaned['marital'].value_counts(dropna=False)\n","\n","# Normalizar texto: minúsculas y quitar espacios\n","df_cleaned['marital'] = df_cleaned['marital'].astype(str).str.strip().str.lower()\n","\n","# Correcciones de escritura y agrupaciones\n","df_cleaned['marital'] = df_cleaned['marital'].replace({\n","    'nan': 'unknown',         \n","    'none': 'unknown'\n","})\n","\n","# Reemplazar valores nulos reales (NaN) por 'unknown'\n","df_cleaned['marital'] = df_cleaned['marital'].fillna('unknown')\n","\n","# Verificación final\n","print(\"Valores únicos normalizados:\")\n","print(df_cleaned['marital'].value_counts())\n"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de variable Education"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Normalización\n","df_cleaned['education'] = df_cleaned['education'].astype(str).str.strip().str.lower()\n","\n","# Correcciones de texto\n","df_cleaned['education'] = df_cleaned['education'].replace({\n","    'basic.4y': 'primary',\n","    'basic.6y': 'primary',\n","    'basic.9y': 'secondary',\n","    'university.degree': 'tertiary',\n","    'high.school': 'secondary',\n","    'illiterate': 'primary',\n","    'nan': 'unknown',\n","    'none': 'unknown'\n","})\n","\n","# Reemplazo de nulos por 'unknown'\n","df_cleaned['education'] = df_cleaned['education'].fillna('unknown')\n","\n","print(df_cleaned['education'].value_counts())\n","\n","imputacion_por_job = {\n","    'management': 'tertiary',\n","    'technician': 'tertiary',\n","    'entrepreneur': 'tertiary',\n","    'self-employed': 'tertiary',\n","    'admin': 'secondary',\n","    'services': 'secondary',\n","    'blue-collar': 'primary',\n","    'housemaid': 'primary',\n","    'unemployed': 'primary',\n","    'student': 'tertiary',\n","    'retired': 'unknown',\n","    'unknown': 'unknown'\n","}\n","\n","mask = (df_cleaned['education'].isin(['unknown', 'nan'])) & (df_cleaned['job'].notna())\n","df_cleaned.loc[mask, 'education'] = df_cleaned.loc[mask, 'job'].map(imputacion_por_job).fillna('unknown')"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable Default"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_cleaned['default'].value_counts(dropna=False)\n","\n","# Normalizar texto (en caso de que existan valores 'yes'/'no' en lugar de booleanos)\n","df_cleaned['default'] = df_cleaned['default'].astype(str).str.strip().str.lower()\n","\n","df_cleaned['default'] = df_cleaned['default'].replace({\n","    'yes': True,\n","    'no': False,\n","    'nan': None,\n","    'none': None\n","})\n","\n","# Convertir a tipo booleano\n","df_cleaned['default'] = df_cleaned['default'].astype('boolean')\n","\n","# Verificar distribución\n","print(df_cleaned['default'].value_counts(dropna=False))\n","\n","# Imputación con False (más del 93% son FALSE - tiene sentido)\n","df_cleaned['default'] = df_cleaned['default'].fillna(False)"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable Housing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Normalizar texto\n","df_cleaned['housing'] = df_cleaned['housing'].astype(str).str.strip().str.lower()\n","\n","# Reemplazar valores por booleanos\n","df_cleaned['housing'] = df_cleaned['housing'].replace({\n","    'yes': True,\n","    'no': False,\n","    'nan': np.nan,\n","    'none': np.nan\n","})\n","\n","# Convertir a tipo booleano\n","df_cleaned['housing'] = df_cleaned['housing'].astype('boolean')\n"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable Loan"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Normalizar texto a minúsculas y eliminar espacios\n","df_cleaned['loan'] = df_cleaned['loan'].astype(str).str.strip().str.lower()\n","\n","# Reemplazar por valores booleanos\n","df_cleaned['loan'] = df_cleaned['loan'].replace({\n","    'yes': True,\n","    'no': False,\n","    'nan': np.nan,\n","    'none': np.nan\n","})\n","\n","# Convertir a tipo booleano nativo\n","df_cleaned['loan'] = df_cleaned['loan'].astype('boolean')"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable Date"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convertir a numérico y manejar nulos o strings\n","df_cleaned['day'] = pd.to_numeric(df_cleaned['day'], errors='coerce')\n","\n","# Eliminar registros con valores fuera del rango 1–31\n","df_cleaned = df_cleaned[(df_cleaned['day'] >= 1) & (df_cleaned['day'] <= 31)]\n","\n","# Convertir a entero\n","df_cleaned['day'] = df_cleaned['day'].astype('Int64')"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable Duration y la variable Y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_cleaned['y'] = (\n","    df_cleaned['y']\n","    .astype(str)\n","    .str.strip()\n","    .str.lower()\n",")\n","\n","# Reemplazar valores válidos y convertir a booleano\n","df_cleaned['y'] = df_cleaned['y'].replace({\n","    'yes': True,\n","    'no': False,\n","    'nan': np.nan,\n","    'none': np.nan\n","})\n","df_cleaned['y'] = df_cleaned['y'].astype('boolean')\n","\n","# 2️Verificar coherencia entre 'y' y 'duration' si duration == 0 → y debe ser False\n","inconsistentes = df_cleaned[(df_cleaned['duration'] == 0) & (df_cleaned['y'] == True)]\n","print(f\"Registros inconsistentes encontrados: {len(inconsistentes)}\")\n","\n","# Corregir inconsistencias\n","df_cleaned.loc[(df_cleaned['duration'] == 0) & (df_cleaned['y'] == True), 'y'] = False\n","\n","# 3️Verificar distribución final de y\n","print(\"\\nDistribución de la variable objetivo (ya limpia):\")\n","print(df_cleaned['y'].value_counts(dropna=False))\n","\n","# 4Eliminar la variable 'duration' \n","df_cleaned = df_cleaned.drop(columns=['duration'])\n","print(\"\\nVariable 'duration' eliminada del dataset limpio (para modelado realista).\")"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable Campaign"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["count      3002.0\n","mean     2.531312\n","std      2.131276\n","min           1.0\n","25%           1.0\n","50%           2.0\n","75%           3.0\n","max          14.0\n","Name: campaign, dtype: Float64\n"]}],"source":["df_cleaned['campaign'].value_counts(dropna=False)\n","\n","# Asegurar tipo numérico\n","df_cleaned['campaign'] = pd.to_numeric(df_cleaned['campaign'], errors='coerce')\n","\n","# valores extremos \n","q99 = df_cleaned['campaign'].quantile(0.99)\n","df_cleaned.loc[df_cleaned['campaign'] > q99, 'campaign'] = np.nan\n","\n","# Convertir a tipo entero (usando Int64 para permitir NaN)\n","df_cleaned['campaign'] = df_cleaned['campaign'].astype('Int64')\n","\n","# Imputar valores faltantes (opcional)\n","median_campaign = df_cleaned['campaign'].median()\n","df_cleaned['campaign'] = df_cleaned['campaign'].fillna(median_campaign)\n","\n","# Verificar resultados\n","print(df_cleaned['campaign'].describe())\n"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable pdays"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Asegurar tipo numérico\n","df_cleaned['pdays'] = pd.to_numeric(df_cleaned['pdays'], errors='coerce')\n","\n","# Reemplazar el valor especial -1 por NaN (sin contacto previo)\n","df_cleaned.loc[df_cleaned['pdays'] == -1, 'pdays'] = np.nan\n","\n","# 3Convertir a tipo entero (usando Int64 para permitir NaN)\n","df_cleaned['pdays'] = df_cleaned['pdays'].astype('Int64')\n","\n","# Verificar distribución final\n","print(df_cleaned['pdays'].describe())\n","print(\"\\nValores nulos totales:\", df_cleaned['pdays'].isna().sum())"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable previous"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Asegurar tipo numérico\n","df_cleaned['previous'] = pd.to_numeric(df_cleaned['previous'], errors='coerce')\n","\n","# Reemplazar valores negativos por NaN (no deberían existir)\n","df_cleaned.loc[df_cleaned['previous'] < 0, 'previous'] = np.nan\n","\n","# Detectar y tratar outliers (por encima del percentil 99)\n","q99 = df_cleaned['previous'].quantile(0.99)\n","df_cleaned.loc[df_cleaned['previous'] > q99, 'previous'] = np.nan\n","\n","# Convertir a entero (usando Int64 para permitir NaN)\n","df_cleaned['previous'] = df_cleaned['previous'].astype('Int64')\n","\n","# No imputar los nulos: si previous = 0 o NaN, indica cliente nuevo\n","print(df_cleaned['previous'].describe())\n","\n","inconsistentes_prev = df_cleaned[(df_cleaned['previous'] == 0) & (df_cleaned['pdays'].notna())]\n","print(f\"Registros inconsistentes encontrados entre 'previous' y 'pdays': {len(inconsistentes_prev)}\")\n","\n","# Corrección automática:\n","df_cleaned.loc[(df_cleaned['previous'] == 0) & (df_cleaned['pdays'].notna()), 'pdays'] = np.nan\n"]},{"cell_type":"markdown","metadata":{},"source":["### Tratamiento de la variable Poutcome"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["poutcome\n","unknown    2364\n","failure     306\n","other       129\n","NaN         120\n","success      83\n","Name: count, dtype: int64\n","poutcome\n","nonexistent    2364\n","failure         306\n","NaN             249\n","success          83\n","Name: count, dtype: int64\n","Registros inconsistentes entre 'previous' y 'poutcome': 0\n"]}],"source":["print(df_cleaned['poutcome'].value_counts(dropna=False))\n","\n","# Normalizar texto\n","df_cleaned['poutcome'] = (\n","    df_cleaned['poutcome']\n","    .astype(str)\n","    .str.strip()\n","    .str.lower()\n",")\n","\n","# Corregir variantes mal escritas o inconsistentes\n","df_cleaned['poutcome'] = df_cleaned['poutcome'].replace({\n","    'nonexistant': 'nonexistent', \n","    'unknown': 'nonexistent',\n","    'none': 'nonexistent',\n","    'nan': np.nan\n","})\n","\n","# Convertir a tipo categórico ordenado\n","df_cleaned['poutcome'] = pd.Categorical(\n","    df_cleaned['poutcome'],\n","    categories=['failure', 'nonexistent', 'success'],\n","    ordered=False\n",")\n","\n","# Verificar resultados\n","print(df_cleaned['poutcome'].value_counts(dropna=False))\n","\n","inconsistentes_pout = df_cleaned[\n","    (df_cleaned['previous'] == 0) & (df_cleaned['poutcome'] == 'success')\n","]\n","print(f\"Registros inconsistentes entre 'previous' y 'poutcome': {len(inconsistentes_pout)}\")\n","\n","# Corrección automática:\n","df_cleaned.loc[(df_cleaned['previous'] == 0), 'poutcome'] = 'nonexistent'"]},{"cell_type":"markdown","metadata":{},"source":["# Pretratamiento de datos - normalización"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":2}
